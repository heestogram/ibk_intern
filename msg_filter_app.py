# msg_filter_app.py
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from lime.lime_text import LimeTextExplainer
import numpy as np



MAX_LEN = 100
MIN_LEN = 15

@st.cache_resource
def load_model():
    model = AutoModelForSequenceClassification.from_pretrained("anthj/naviyam-msg")
    tokenizer = AutoTokenizer.from_pretrained("anthj/naviyam-msg")
    return model, tokenizer

model, tokenizer = load_model()

def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}  
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        probs = outputs.logits.softmax(dim=-1)
        label = "ê¸ì •" if probs[0][1] > 0.5 else "ë¶€ì •"
        return label, probs[0][1].item()

def model_predict_proba(texts):
    inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs.to(model.device))
        probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()
    return probs

st.title("ğŸ“Œ ê°ì‚¬ ë©”ì‹œì§€ í•„í„°ë§ í…ŒìŠ¤íŠ¸")

if st.button("ğŸ Homeìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
    st.session_state.page = "main"

user_input = st.text_area(
    "ìˆ˜í˜œìê°€ ë³´ë‚¸ ê°ì‚¬ ë©”ì‹œì§€", 
    height=150,
    max_chars=MAX_LEN,
    key="message_input"
)

# ê¸€ì ìˆ˜ ì¹´ìš´í„° í‘œì‹œ (ìš°ì¸¡ í•˜ë‹¨ì—)
char_count = len(user_input)
# st.markdown(
#     f"<div style='text-align: right; color: gray;'>{char_count}/{MAX_LEN}</div>", 
#     unsafe_allow_html=True
# )

# ê²€ì‚¬ ë²„íŠ¼
if st.button("âœ”ï¸ ê²€ì‚¬í•˜ê¸°"):
    if char_count < MIN_LEN:
        st.warning(f"ë©”ì‹œì§€ëŠ” ìµœì†Œ {MIN_LEN}ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        label, prob = predict_sentiment(user_input)

        if label == "ê¸ì •" and prob >= 0.82:
            st.success(f"âœ… ë©”ì‹œì§€ì— ë¬¸ì œ ì—†ì–´ ë³´ì—¬ìš”! (ê¸ì • í™•ë¥ : {prob:.2f})")
        else:
            st.error(f"ğŸš« ì£¼ì˜! ë¶€ì ì ˆí•œ í‘œí˜„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¸ì • í™•ë¥ : {prob:.2f})")

            # LIME í•˜ì´ë¼ì´íŒ…
            st.markdown("### ğŸ” ê°ì •ì— ì˜í–¥ì„ ì¤€ ë‹¨ì–´ë“¤ (LIME)")
            explainer = LimeTextExplainer(class_names=["ë¶€ì •", "ê¸ì •"], char_level=False)

            explanation = explainer.explain_instance(
                user_input,
                model_predict_proba,
                num_features=6,
                num_samples=300  # 1000~1500 ì ë‹¹
            )
            # í•˜ì´ë¼ì´íŒ… ë Œë”ë§
            highlighted_html = explanation.as_html()
            st.components.v1.html(highlighted_html, height=400, scrolling=True)