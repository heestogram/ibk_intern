# msg_filter_app.py
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from lime.lime_text import LimeTextExplainer
import numpy as np



MAX_LEN = 100
MIN_LEN = 15

@st.cache_resource
def load_model():
    model = AutoModelForSequenceClassification.from_pretrained("anthj/naviyam-msg")
    tokenizer = AutoTokenizer.from_pretrained("anthj/naviyam-msg")
    return model, tokenizer

model, tokenizer = load_model()

def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}  
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        probs = outputs.logits.softmax(dim=-1)
        label = "ê¸ì •" if probs[0][1] > 0.5 else "ë¶€ì •"
        return label, probs[0][1].item()

def model_predict_proba(texts):
    inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs.to(model.device))
        probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()
    return probs

if st.button("ğŸ Homeìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
    st.session_state.page = "main"

st.title("ğŸ“Œ ê°ì‚¬ ë©”ì‹œì§€ í•„í„°ë§ í…ŒìŠ¤íŠ¸")



user_input = st.text_area(
    "ìˆ˜í˜œìê°€ ë³´ë‚¸ ê°ì‚¬ ë©”ì‹œì§€", 
    height=150,
    max_chars=MAX_LEN,
    key="message_input"
)

# ê¸€ì ìˆ˜ ì¹´ìš´í„° í‘œì‹œ (ìš°ì¸¡ í•˜ë‹¨ì—)
char_count = len(user_input)
# st.markdown(
#     f"<div style='text-align: right; color: gray;'>{char_count}/{MAX_LEN}</div>", 
#     unsafe_allow_html=True
# )

if st.button("âœ”ï¸ ê²€ì‚¬í•˜ê¸°"):
    if char_count < MIN_LEN:
        st.warning(f"ë©”ì‹œì§€ëŠ” ìµœì†Œ {MIN_LEN}ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        label, prob = predict_sentiment(user_input)

        if label == "ê¸ì •" and prob >= 0.82:
            st.success(f"âœ… ë©”ì‹œì§€ì— ë¬¸ì œ ì—†ì–´ ë³´ì—¬ìš”! (ê¸ì • í™•ë¥ : {prob:.2f})")
        else:
            st.error(f"ğŸš« ì£¼ì˜! ë¶€ì ì ˆí•œ í‘œí˜„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¸ì • í™•ë¥ : {prob:.2f})")

            st.markdown("### âœ… ë¬¸ì œê°€ ë ë§Œí•œ ë¶€ë¶„ì„ ë°”ê¿”ë´ìš”!")
            explainer = LimeTextExplainer(class_names=["ë¶€ì •", "ê¸ì •"], char_level=False)

            explanation = explainer.explain_instance(
                user_input,
                model_predict_proba,
                num_features=10,
                num_samples=300
            )
            

            # ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤€ ë‹¨ì–´ë§Œ ì¶”ì¶œ
            negative_words = {
                word: weight
                for word, weight in explanation.as_list(label=1)
                if weight < 0
            }

            # ë¶€ì • ë‹¨ì–´ê°€ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            if not negative_words:
                st.info("ğŸ“˜ ë¶€ì •ì ì¸ ë‹¨ì–´ê°€ ëª…í™•íˆ ë“œëŸ¬ë‚˜ì§„ ì•Šì•„ìš”.")
            else:
                # ì›ë¬¸ í…ìŠ¤íŠ¸ì—ì„œ ë¶€ì • ë‹¨ì–´ ê°•ì¡°
                highlighted_text = user_input
                for word in sorted(negative_words, key=len, reverse=True):
                    highlighted_text = highlighted_text.replace(
                        word, f"<mark style='background-color: #FF9999'>{word}</mark>"
                    )

                st.markdown("#### ğŸ“ ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤€ ë‹¨ì–´ í•˜ì´ë¼ì´íŒ…")
                st.markdown(f"<div style='line-height:1.6;'>{highlighted_text}</div>", unsafe_allow_html=True)